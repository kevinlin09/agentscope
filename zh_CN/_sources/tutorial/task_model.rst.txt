
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/task_model.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_tutorial_task_model.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_task_model.py:


.. _model:

æ¨¡å‹
====================

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä»‹ç» AgentScope ä¸­é›†æˆçš„æ¨¡å‹ APIã€å¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Œä»¥åŠå¦‚ä½•é›†æˆæ–°çš„æ¨¡å‹ APIã€‚
AgentScope ç›®å‰æ”¯æŒçš„æ¨¡å‹ API å’Œæ¨¡å‹æä¾›å•†åŒ…æ‹¬ï¼š

.. list-table::
    :header-rows: 1

    * - API
      - ç±»
      - å…¼å®¹
      - æµå¼
      - å·¥å…·
      - è§†è§‰
      - æ¨ç†
    * - OpenAI
      - ``OpenAIChatModel``
      - vLLM, DeepSeek
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - DashScope
      - ``DashScopeChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Anthropic
      - ``AnthropicChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Gemini
      - ``GeminiChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Ollama
      - ``OllamaChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…

.. note:: å½“ä½¿ç”¨ vLLM æ—¶ï¼Œéœ€è¦åœ¨éƒ¨ç½²æ—¶ä¸ºä¸åŒæ¨¡å‹é…ç½®ç›¸åº”çš„å·¥å…·è°ƒç”¨å‚æ•°ï¼Œä¾‹å¦‚ ``--enable-auto-tool-choice``ã€``--tool-call-parser`` ç­‰å‚æ•°ã€‚æ›´å¤šè¯¦æƒ…è¯·å‚è€ƒ `vLLM å®˜æ–¹æ–‡æ¡£ <https://docs.vllm.ai/en/latest/features/tool_calling.html>`_ã€‚

.. note:: å…¼å®¹ OpenAI API çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ vLLM éƒ¨ç½²çš„æ¨¡å‹ï¼‰ï¼Œæ¨èä½¿ç”¨ ``OpenAIChatModel``ï¼Œå¹¶é€šè¿‡ ``client_args={"base_url": "http://your-api-endpoint"}`` å‚æ•°æŒ‡å®š API ç«¯ç‚¹ã€‚ä¾‹å¦‚ï¼š

    .. code-block:: python

        OpenAIChatModel(client_args={"base_url": "http://localhost:8000/v1"})

.. note:: æ¨¡å‹çš„è¡Œä¸ºå‚æ•°ï¼ˆå¦‚æ¸©åº¦ã€æœ€å¤§é•¿åº¦ç­‰ï¼‰å¯ä»¥é€šè¿‡ ``generate_kwargs`` å‚æ•°åœ¨æ„é€ å‡½æ•°ä¸­æå‰è®¾å®šã€‚ä¾‹å¦‚ï¼š

    .. code-block:: python

        OpenAIChatModel(generate_kwargs={"temperature": 0.3, "max_tokens": 1000})

ä¸ºäº†æä¾›ç»Ÿä¸€çš„æ¨¡å‹æ¥å£ï¼Œä¸Šè¿°æ‰€æœ‰ç±»å‡è¢«ç»Ÿä¸€ä¸ºï¼š

- ``__call__`` å‡½æ•°çš„å‰ä¸‰ä¸ªå‚æ•°æ˜¯ ``messages``ï¼Œ``tools`` å’Œ ``tool_choice``ï¼Œåˆ†åˆ«æ˜¯è¾“å…¥æ¶ˆæ¯ï¼Œå·¥å…·å‡½æ•°çš„ JSON schemaï¼Œä»¥åŠå·¥å…·é€‰æ‹©çš„æ¨¡å¼ã€‚
- éæµå¼è¿”å›æ—¶ï¼Œè¿”å›ç±»å‹æ˜¯ ``ChatResponse`` å®ä¾‹ï¼›æµå¼è¿”å›æ—¶ï¼Œè¿”å›çš„æ˜¯ ``ChatResponse`` çš„å¼‚æ­¥ç”Ÿæˆå™¨ã€‚

.. note:: ä¸åŒçš„æ¨¡å‹ API åœ¨è¾“å…¥æ¶ˆæ¯æ ¼å¼ä¸Šæœ‰æ‰€ä¸åŒï¼ŒAgentScope é€šè¿‡ formatter æ¨¡å—å¤„ç†æ¶ˆæ¯çš„è½¬æ¢ï¼Œè¯·å‚è€ƒ :ref:`format`ã€‚

``ChatResponse`` åŒ…å«å¤§æ¨¡å‹ç”Ÿæˆçš„æ¨ç†/æ–‡æœ¬/å·¥å…·ä½¿ç”¨å†…å®¹ã€èº«ä»½ã€åˆ›å»ºæ—¶é—´å’Œä½¿ç”¨ä¿¡æ¯ã€‚

.. GENERATED FROM PYTHON SOURCE LINES 80-105

.. code-block:: Python

    import asyncio
    import json
    import os

    from agentscope.message import TextBlock, ToolUseBlock, ThinkingBlock, Msg
    from agentscope.model import ChatResponse, DashScopeChatModel

    response = ChatResponse(
        content=[
            ThinkingBlock(
                type="thinking",
                thinking="æˆ‘åº”è¯¥åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚",
            ),
            TextBlock(type="text", text="æˆ‘å°†åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚"),
            ToolUseBlock(
                type="tool_use",
                id="642n298gjna",
                name="google_search",
                input={"query": "AgentScope"},
            ),
        ],
    )

    print(response)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ChatResponse(content=[{'type': 'thinking', 'thinking': 'æˆ‘åº”è¯¥åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚'}, {'type': 'text', 'text': 'æˆ‘å°†åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚'}, {'type': 'tool_use', 'id': '642n298gjna', 'name': 'google_search', 'input': {'query': 'AgentScope'}}], id='2025-10-27 10:17:24.222_0f1a57', created_at='2025-10-27 10:17:24.222', type='chat', usage=None, metadata=None)




.. GENERATED FROM PYTHON SOURCE LINES 106-107

ä»¥ ``DashScopeChatModel`` ä¸ºä¾‹ï¼Œè°ƒç”¨å’Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š

.. GENERATED FROM PYTHON SOURCE LINES 107-132

.. code-block:: Python



    async def example_model_call() -> None:
        """ä½¿ç”¨ DashScopeChatModel çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-max",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            stream=False,
        )

        res = await model(
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼"},
            ],
        )

        # æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨å“åº”å†…å®¹åˆ›å»º ``Msg`` å¯¹è±¡
        msg_res = Msg("Friday", res.content, "assistant")

        print("LLM è¿”å›ç»“æœ:", res)
        print("ä½œä¸º Msg çš„å“åº”:", msg_res)


    asyncio.run(example_model_call())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    LLM è¿”å›ç»“æœ: ChatResponse(content=[{'type': 'text', 'text': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}], id='2025-10-27 10:17:25.725_ec6fdf', created_at='2025-10-27 10:17:25.725', type='chat', usage=ChatUsage(input_tokens=10, output_tokens=7, time=1.501503, type='chat'), metadata=None)
    ä½œä¸º Msg çš„å“åº”: Msg(id='3NjW9BMFmNFaSGAdtRwyBH', name='Friday', content=[{'type': 'text', 'text': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}], role='assistant', metadata=None, timestamp='2025-10-27 10:17:25.725', invocation_id='None')




.. GENERATED FROM PYTHON SOURCE LINES 133-140

æµå¼è¿”å›
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
è¦å¯ç”¨æµå¼è¿”å›ï¼Œè¯·åœ¨æ¨¡å‹çš„æ„é€ å‡½æ•°ä¸­å°† ``stream`` å‚æ•°è®¾ç½®ä¸º ``True``ã€‚
æµå¼è¿”å›ä¸­ï¼Œ``__call__`` æ–¹æ³•å°†è¿”å›ä¸€ä¸ª **å¼‚æ­¥ç”Ÿæˆå™¨**ï¼Œè¯¥ç”Ÿæˆå™¨è¿­ä»£è¿”å› ``ChatResponse`` å®ä¾‹ã€‚

.. note:: AgentScope ä¸­çš„æµå¼è¿”å›ç»“æœä¸º **ç´¯åŠ å¼**ï¼Œè¿™æ„å‘³ç€æ¯ä¸ª chunk ä¸­çš„å†…å®¹åŒ…å«æ‰€æœ‰ä¹‹å‰çš„å†…å®¹åŠ ä¸Šæ–°ç”Ÿæˆçš„å†…å®¹ã€‚


.. GENERATED FROM PYTHON SOURCE LINES 140-170

.. code-block:: Python



    async def example_streaming() -> None:
        """ä½¿ç”¨æµå¼æ¨¡å‹çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-max",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            stream=True,
        )

        generator = await model(
            messages=[
                {
                    "role": "user",
                    "content": "ä» 1 æ•°åˆ° 20ï¼ŒåªæŠ¥å‘Šæ•°å­—ï¼Œä¸è¦ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚",
                },
            ],
        )
        print("å“åº”çš„ç±»å‹:", type(generator))

        i = 0
        async for chunk in generator:
            print(f"å— {i}")
            print(f"\tç±»å‹: {type(chunk.content)}")
            print(f"\t{chunk}\n")
            i += 1


    asyncio.run(example_streaming())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    å“åº”çš„ç±»å‹: <class 'async_generator'>
    å— 0
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1'}], id='2025-10-27 10:17:26.908_d145f7', created_at='2025-10-27 10:17:26.908', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=1, time=1.181833, type='chat'), metadata=None)

    å— 1
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n'}], id='2025-10-27 10:17:26.957_d20392', created_at='2025-10-27 10:17:26.957', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=2, time=1.230336, type='chat'), metadata=None)

    å— 2
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3'}], id='2025-10-27 10:17:27.007_c316ff', created_at='2025-10-27 10:17:27.008', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=5, time=1.281016, type='chat'), metadata=None)

    å— 3
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n'}], id='2025-10-27 10:17:27.057_703de2', created_at='2025-10-27 10:17:27.057', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=8, time=1.330469, type='chat'), metadata=None)

    å— 4
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n'}], id='2025-10-27 10:17:27.488_e83fa9', created_at='2025-10-27 10:17:27.488', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=14, time=1.761371, type='chat'), metadata=None)

    å— 5
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10'}], id='2025-10-27 10:17:27.648_1c60e0', created_at='2025-10-27 10:17:27.648', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=20, time=1.921483, type='chat'), metadata=None)

    å— 6
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12'}], id='2025-10-27 10:17:27.729_439b3a', created_at='2025-10-27 10:17:27.729', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=26, time=2.002413, type='chat'), metadata=None)

    å— 7
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14'}], id='2025-10-27 10:17:27.830_baf46a', created_at='2025-10-27 10:17:27.830', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=32, time=2.103338, type='chat'), metadata=None)

    å— 8
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16'}], id='2025-10-27 10:17:27.947_0ab69f', created_at='2025-10-27 10:17:27.947', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=38, time=2.220122, type='chat'), metadata=None)

    å— 9
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18'}], id='2025-10-27 10:17:28.273_d3bd87', created_at='2025-10-27 10:17:28.273', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=44, time=2.546576, type='chat'), metadata=None)

    å— 10
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20'}], id='2025-10-27 10:17:28.376_f44776', created_at='2025-10-27 10:17:28.376', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=50, time=2.649494, type='chat'), metadata=None)

    å— 11
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20'}], id='2025-10-27 10:17:28.454_cc0dde', created_at='2025-10-27 10:17:28.454', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=50, time=2.727307, type='chat'), metadata=None)





.. GENERATED FROM PYTHON SOURCE LINES 171-175

æ¨ç†æ¨¡å‹
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
AgentScope é€šè¿‡æä¾› ``ThinkingBlock`` æ¥æ”¯æŒæ¨ç†æ¨¡å‹ã€‚


.. GENERATED FROM PYTHON SOURCE LINES 175-200

.. code-block:: Python



    async def example_reasoning() -> None:
        """ä½¿ç”¨æ¨ç†æ¨¡å‹çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-turbo",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            enable_thinking=True,
        )

        res = await model(
            messages=[
                {"role": "user", "content": "æˆ‘æ˜¯è°ï¼Ÿ"},
            ],
        )

        last_chunk = None
        async for chunk in res:
            last_chunk = chunk
        print("æœ€ç»ˆå“åº”:")
        print(last_chunk)


    asyncio.run(example_reasoning())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    æœ€ç»ˆå“åº”:
    ChatResponse(content=[{'type': 'thinking', 'thinking': 'å¥½çš„ï¼Œç”¨æˆ·é—®â€œæˆ‘æ˜¯è°ï¼Ÿâ€ï¼Œè¿™æ˜¯ä¸€ä¸ªå“²å­¦æ€§çš„é—®é¢˜ï¼Œå¯èƒ½éœ€è¦ä»ä¸åŒè§’åº¦æ¥å›ç­”ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„èƒŒæ™¯å’Œæ„å›¾ã€‚ä»–å¯èƒ½æ˜¯åœ¨æ€è€ƒè‡ªæˆ‘èº«ä»½ï¼Œæˆ–è€…å¯¹å­˜åœ¨æ„Ÿåˆ°å›°æƒ‘ï¼Œä¹Ÿå¯èƒ½æ˜¯åœ¨è¿›è¡ŒæŸç§å¿ƒç†æ¢ç´¢ã€‚\n\næ¥ä¸‹æ¥ï¼Œæˆ‘åº”è¯¥åˆ†æè¿™ä¸ªé—®é¢˜çš„ä¸åŒå±‚é¢ã€‚ä»å¿ƒç†å­¦è§’åº¦ï¼Œè‡ªæˆ‘è®¤çŸ¥æ¶‰åŠä¸ªäººçš„èº«ä»½è®¤åŒã€ä»·å€¼è§‚å’Œç»å†ã€‚å“²å­¦ä¸Šï¼Œè¿™å¯èƒ½æ¶‰åŠåˆ°æœ¬ä½“è®ºï¼Œæ¢è®¨å­˜åœ¨çš„æœ¬è´¨ã€‚å®—æ•™æˆ–çµæ€§æ–¹é¢ï¼Œå¯èƒ½æœ‰ä¸åŒçš„è§£é‡Šï¼Œæ¯”å¦‚çµé­‚æˆ–æ›´é«˜çš„è‡ªæˆ‘ã€‚\n\nç„¶åï¼Œæˆ‘éœ€è¦è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„æ·±å±‚éœ€æ±‚ã€‚ä»–å¯èƒ½æ­£åœ¨ç»å†èº«ä»½å±æœºï¼Œæˆ–è€…å¯»æ±‚è‡ªæˆ‘ç†è§£ã€‚è¿™æ—¶å€™ï¼Œæä¾›ä¸€ä¸ªå¼€æ”¾æ€§çš„å›ç­”ï¼Œé¼“åŠ±ä»–åæ€è‡ªå·±çš„ç»å†å’Œä»·å€¼è§‚ä¼šæ›´åˆé€‚ã€‚\n\nè¿˜è¦æ³¨æ„é¿å…ç»™å‡ºè¿‡äºç¬¼ç»Ÿæˆ–æŠ½è±¡çš„ç­”æ¡ˆï¼Œåº”è¯¥ç»“åˆå…·ä½“çš„ä¾‹å­æˆ–æ–¹æ³•ï¼Œå¸®åŠ©ç”¨æˆ·è¿›è¡Œè‡ªæˆ‘æ¢ç´¢ã€‚æ¯”å¦‚å»ºè®®ä»–é€šè¿‡å›é¡¾è¿‡å»çš„ç»å†ã€æ€è€ƒè‡ªå·±çš„ä»·å€¼è§‚ã€ä¸ä»–äººäº’åŠ¨ç­‰æ–¹å¼æ¥ç†è§£è‡ªå·±ã€‚\n\nå¦å¤–ï¼Œè¦ç¡®ä¿å›ç­”çš„è¯­æ°”å‹å¥½ä¸”æ”¯æŒï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°è¢«ç†è§£å’Œæ¥çº³ã€‚å¯èƒ½è¿˜éœ€è¦æé†’ä»–ï¼Œè‡ªæˆ‘è®¤çŸ¥æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œä¸éœ€è¦æ€¥äºæ‰¾åˆ°ç­”æ¡ˆã€‚\n\næœ€åï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–‡åŒ–æˆ–ä¸ªäººå·®å¼‚éœ€è¦è€ƒè™‘ï¼Œç¡®ä¿å›ç­”çš„æ™®éé€‚ç”¨æ€§ï¼ŒåŒæ—¶ä¿æŒä¸­ç«‹å’Œå®¢è§‚ã€‚'}, {'type': 'text', 'text': 'â€œæˆ‘æ˜¯è°ï¼Ÿâ€è¿™ä¸ªé—®é¢˜çœ‹ä¼¼ç®€å•ï¼Œå´å¯èƒ½å¼•å‘æ·±åˆ»çš„æ€è€ƒã€‚å®ƒå¯èƒ½æŒ‡å‘å¯¹è‡ªæˆ‘èº«ä»½ã€å­˜åœ¨æ„ä¹‰æˆ–å†…å¿ƒæœ¬è´¨çš„æ¢ç´¢ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½çš„è§†è§’ï¼Œæˆ–è®¸èƒ½å¸®åŠ©ä½ æ›´æ¥è¿‘è‡ªå·±çš„ç­”æ¡ˆï¼š\n\n---\n\n### 1. **ä»ç»éªŒä¸ç»å†å‡ºå‘**  \n   - **ä½ æ˜¯ä½ çš„ç»å†**ï¼šä½ è¿‡å»çš„é€‰æ‹©ã€æƒ…æ„Ÿã€æŒ‘æˆ˜å’Œæˆå°±å¡‘é€ äº†ç°åœ¨çš„ä½ ã€‚æ¯”å¦‚ï¼Œä½ å¯èƒ½æ˜¯ä¸€ä¸ªçƒ­çˆ±è‰ºæœ¯çš„äººï¼Œæˆ–æ˜¯ä¸€ä¸ªåœ¨å›°å¢ƒä¸­åšæŒçš„äººã€‚  \n   - **ä½ æ˜¯ä½ çš„ä¹ æƒ¯ä¸ä»·å€¼è§‚**ï¼šä½ æ¯å¤©çš„è¡Œä¸ºæ¨¡å¼ã€å¯¹å–„æ¶çš„åˆ¤æ–­ã€å¯¹ç”Ÿæ´»çš„æ€åº¦ï¼Œéƒ½åœ¨å®šä¹‰ä½ ã€‚\n\n---\n\n### 2. **ä»å“²å­¦è§’åº¦æ€è€ƒ**  \n   - **â€œæˆ‘â€æ˜¯æµåŠ¨çš„**ï¼šå“²å­¦å®¶å¦‚èµ«æ‹‰å…‹åˆ©ç‰¹è¯´â€œäººä¸èƒ½ä¸¤æ¬¡è¸å…¥åŒä¸€æ¡æ²³æµâ€ï¼Œä½ çš„èº«ä»½å¯èƒ½åœ¨ä¸æ–­å˜åŒ–ã€‚ä»Šå¤©çš„ä½ å¯èƒ½ä¸æ˜¨å¤©çš„ä½ æœ‰æ‰€ä¸åŒã€‚  \n   - **â€œæˆ‘â€æ˜¯æ„è¯†çš„è§‚å¯Ÿè€…**ï¼šæœ‰äº›å“²å­¦è®¤ä¸ºï¼Œâ€œæˆ‘â€æ˜¯è§‚å¯Ÿä¸–ç•Œã€æ€è€ƒé—®é¢˜çš„ä¸»ä½“ï¼Œè€Œâ€œæˆ‘â€æœ¬èº«å¯èƒ½è¶…è¶Šå…·ä½“çš„èº«ä½“æˆ–æ€æƒ³ã€‚\n\n---\n\n### 3. **ä»å¿ƒç†å­¦è§†è§’**  \n   - **è‡ªæˆ‘è®¤çŸ¥çš„å±‚æ¬¡**ï¼šå¿ƒç†å­¦å®¶è£æ ¼æå‡ºâ€œè‡ªæˆ‘â€åŒ…å«æ„è¯†ï¼ˆæ˜¾æ€§çš„è‡ªæˆ‘ï¼‰å’Œæ— æ„è¯†ï¼ˆéšè—çš„æ½œèƒ½ï¼‰ã€‚ä½ å¯èƒ½éœ€è¦é€šè¿‡åæ€æˆ–æ¢ç´¢ï¼Œå‘ç°æ›´æ·±å±‚çš„è‡ªå·±ã€‚  \n   - **ç¤¾ä¼šè§’è‰²ä¸å†…åœ¨æœ¬è´¨**ï¼šä½ å¯èƒ½æ˜¯æŸä¸ªå®¶åº­ä¸­çš„å­©å­ã€èŒåœºä¸­çš„å‘˜å·¥ï¼Œä½†è¿™äº›è§’è‰²åªæ˜¯â€œä½ â€çš„ä¸€éƒ¨åˆ†ï¼Œè€Œéå…¨éƒ¨ã€‚\n\n---\n\n### 4. **ä»çµæ€§æˆ–å­˜åœ¨ä¸»ä¹‰è§’åº¦**  \n   - **â€œæˆ‘æ˜¯â€æ˜¯ä¸€ç§å­˜åœ¨**ï¼šå­˜åœ¨ä¸»ä¹‰è®¤ä¸ºï¼Œäººå…ˆå­˜åœ¨ï¼Œç„¶åé€šè¿‡é€‰æ‹©å®šä¹‰è‡ªå·±ã€‚ä½ å¯èƒ½éœ€è¦ä¸»åŠ¨åˆ›é€ è‡ªå·±çš„æ„ä¹‰ã€‚  \n   - **â€œæˆ‘æ˜¯â€æ˜¯è¿æ¥çš„çº½å¸¦**ï¼šåœ¨çµæ€§ä¼ ç»Ÿä¸­ï¼Œâ€œæˆ‘â€å¯èƒ½è¢«è§†ä¸ºä¸å®‡å®™ã€ä»–äººæˆ–æ›´é«˜åŠ›é‡çš„è¿æ¥ç‚¹ã€‚\n\n---\n\n### 5. **ä¸€ä¸ªç®€å•çš„ç»ƒä¹ **  \n   å¦‚æœä½ æ„Ÿåˆ°å›°æƒ‘ï¼Œå¯ä»¥å°è¯•ä»¥ä¸‹é—®é¢˜ï¼š  \n   - æˆ‘æœ€çè§†çš„æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä¾‹å¦‚ï¼šè‡ªç”±ã€çˆ±ã€çŸ¥è¯†ï¼‰  \n   - æˆ‘å®³æ€•å¤±å»ä»€ä¹ˆï¼Ÿï¼ˆè¿™å¯èƒ½æ­ç¤ºä½ çš„æ ¸å¿ƒéœ€æ±‚ï¼‰  \n   - å¦‚æœæ²¡æœ‰ç¤¾ä¼šæ ‡ç­¾ï¼ˆå¦‚èŒä¸šã€å›½ç±ï¼‰ï¼Œæˆ‘ä¼šå¦‚ä½•å®šä¹‰è‡ªå·±ï¼Ÿ  \n\n---\n\n### æœ€å  \nâ€œæˆ‘æ˜¯è°ï¼Ÿâ€æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œå®ƒå¯èƒ½æ˜¯ä¸€ä¸ªæŒç»­æ¢ç´¢çš„è¿‡ç¨‹ã€‚æœ‰æ—¶ï¼Œç­”æ¡ˆè—åœ¨ä½ åšçš„å°äº‹é‡Œâ€”â€”æ¯”å¦‚ä½ æ„¿æ„ä¸ºä»–äººä»˜å‡ºçš„å–„æ„ï¼Œæˆ–æ˜¯åœ¨æ·±å¤œç‹¬è‡ªæ€è€ƒæ—¶çš„çº¯ç²¹æ„Ÿå—ã€‚å…è®¸è‡ªå·±æ…¢æ…¢é è¿‘è¿™ä¸ªç­”æ¡ˆï¼Œæ— éœ€æ€¥äºæ±‚æˆã€‚ ğŸŒ±'}], id='2025-10-27 10:17:37.199_c82f82', created_at='2025-10-27 10:17:37.199', type='chat', usage=ChatUsage(input_tokens=11, output_tokens=795, time=8.740741, type='chat'), metadata=None)




.. GENERATED FROM PYTHON SOURCE LINES 201-209

å·¥å…· API
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ä¸åŒçš„æ¨¡å‹æä¾›å•†åœ¨å·¥å…· API æ–¹é¢æœ‰æ‰€ä¸åŒï¼Œä¾‹å¦‚å·¥å…· JSON schemaã€å·¥å…·è°ƒç”¨/å“åº”æ ¼å¼ã€‚
ä¸ºäº†æä¾›ç»Ÿä¸€çš„æ¥å£ï¼ŒAgentScope é€šè¿‡ä»¥ä¸‹æ–¹å¼è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼š

- æä¾›äº†ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨ç»“æ„ block :ref:`ToolUseBlock <tool-block>` å’Œå·¥å…·å“åº”ç»“æ„ :ref:`ToolResultBlock <tool-block>`ã€‚
- åœ¨æ¨¡å‹ç±»çš„ ``__call__`` æ–¹æ³•ä¸­æä¾›ç»Ÿä¸€çš„å·¥å…·æ¥å£ ``tools``ï¼Œæ¥å—å·¥å…· JSON schema åˆ—è¡¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š


.. GENERATED FROM PYTHON SOURCE LINES 209-230

.. code-block:: Python


    json_schemas = [
        {
            "type": "function",
            "function": {
                "name": "google_search",
                "description": "åœ¨ Google ä¸Šæœç´¢æŸ¥è¯¢ã€‚",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢æŸ¥è¯¢ã€‚",
                        },
                    },
                    "required": ["query"],
                },
            },
        },
    ]








.. GENERATED FROM PYTHON SOURCE LINES 231-236

è¿›ä¸€æ­¥é˜…è¯»
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- :ref:`message`
- :ref:`prompt`



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 12.982 seconds)


.. _sphx_glr_download_tutorial_task_model.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: task_model.ipynb <task_model.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: task_model.py <task_model.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: task_model.zip <task_model.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
