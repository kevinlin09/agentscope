
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/task_model.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_tutorial_task_model.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_task_model.py:


.. _model:

æ¨¡å‹
====================

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä»‹ç» AgentScope ä¸­é›†æˆçš„æ¨¡å‹ APIã€å¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Œä»¥åŠå¦‚ä½•é›†æˆæ–°çš„æ¨¡å‹ APIã€‚
AgentScope ç›®å‰æ”¯æŒçš„æ¨¡å‹ API å’Œæ¨¡å‹æä¾›å•†åŒ…æ‹¬ï¼š

.. list-table::
    :header-rows: 1

    * - API
      - ç±»
      - å…¼å®¹
      - æµå¼
      - å·¥å…·
      - è§†è§‰
      - æ¨ç†
    * - OpenAI
      - ``OpenAIChatModel``
      - vLLM, DeepSeek
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - DashScope
      - ``DashScopeChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Anthropic
      - ``AnthropicChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Gemini
      - ``GeminiChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Ollama
      - ``OllamaChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…

.. note:: å½“ä½¿ç”¨ vLLM æ—¶ï¼Œæ‚¨éœ€è¦åœ¨éƒ¨ç½²æ—¶ä¸ºä¸åŒæ¨¡å‹é…ç½®ç›¸åº”çš„å·¥å…·è°ƒç”¨å‚æ•°ï¼Œä¾‹å¦‚ ``--enable-auto-tool-choice``ã€``--tool-call-parser`` ç­‰å‚æ•°ã€‚æ›´å¤šè¯¦æƒ…è¯·å‚è€ƒ `vLLM å®˜æ–¹æ–‡æ¡£ <https://docs.vllm.ai/en/latest/features/tool_calling.html>`_ã€‚

ä¸ºäº†æä¾›ç»Ÿä¸€çš„æ¨¡å‹æ¥å£ï¼Œä¸Šè¿°æ‰€æœ‰ç±»å‡è¢«ç»Ÿä¸€ä¸ºï¼š

- ``__call__`` å‡½æ•°çš„å‰ä¸‰ä¸ªå‚æ•°æ˜¯ ``messages``ï¼Œ``tools`` å’Œ ``tool_choice``ï¼Œåˆ†åˆ«æ˜¯è¾“å…¥æ¶ˆæ¯ï¼Œå·¥å…·å‡½æ•°çš„ JSON schemaï¼Œä»¥åŠå·¥å…·é€‰æ‹©çš„æ¨¡å¼ã€‚
- éæµå¼è¿”å›æ—¶ï¼Œè¿”å›ç±»å‹æ˜¯ ``ChatResponse`` å®ä¾‹ï¼›æµå¼è¿”å›æ—¶ï¼Œè¿”å›çš„æ˜¯ ``ChatResponse`` çš„å¼‚æ­¥ç”Ÿæˆå™¨ã€‚

.. note:: ä¸åŒçš„æ¨¡å‹ API åœ¨è¾“å…¥æ¶ˆæ¯æ ¼å¼ä¸Šæœ‰æ‰€ä¸åŒï¼ŒAgentScope é€šè¿‡ formatter æ¨¡å—å¤„ç†æ¶ˆæ¯çš„è½¬æ¢ï¼Œè¯·å‚è€ƒ :ref:`format`ã€‚

``ChatResponse`` åŒ…å«å¤§æ¨¡å‹ç”Ÿæˆçš„æ¨ç†/æ–‡æœ¬/å·¥å…·ä½¿ç”¨å†…å®¹ã€èº«ä»½ã€åˆ›å»ºæ—¶é—´å’Œä½¿ç”¨ä¿¡æ¯ã€‚

.. GENERATED FROM PYTHON SOURCE LINES 68-93

.. code-block:: Python

    import asyncio
    import json
    import os

    from agentscope.message import TextBlock, ToolUseBlock, ThinkingBlock, Msg
    from agentscope.model import ChatResponse, DashScopeChatModel

    response = ChatResponse(
        content=[
            ThinkingBlock(
                type="thinking",
                thinking="æˆ‘åº”è¯¥åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚",
            ),
            TextBlock(type="text", text="æˆ‘å°†åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚"),
            ToolUseBlock(
                type="tool_use",
                id="642n298gjna",
                name="google_search",
                input={"query": "AgentScope"},
            ),
        ],
    )

    print(response)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ChatResponse(content=[{'type': 'thinking', 'thinking': 'æˆ‘åº”è¯¥åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚'}, {'type': 'text', 'text': 'æˆ‘å°†åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚'}, {'type': 'tool_use', 'id': '642n298gjna', 'name': 'google_search', 'input': {'query': 'AgentScope'}}], id='2025-09-20 01:31:30.380_320018', created_at='2025-09-20 01:31:30.380', type='chat', usage=None, metadata=None)




.. GENERATED FROM PYTHON SOURCE LINES 94-95

ä»¥ ``DashScopeChatModel`` ä¸ºä¾‹ï¼Œè°ƒç”¨å’Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š

.. GENERATED FROM PYTHON SOURCE LINES 95-120

.. code-block:: Python



    async def example_model_call() -> None:
        """ä½¿ç”¨ DashScopeChatModel çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-max",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            stream=False,
        )

        res = await model(
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼"},
            ],
        )

        # æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨å“åº”å†…å®¹åˆ›å»º ``Msg`` å¯¹è±¡
        msg_res = Msg("Friday", res.content, "assistant")

        print("LLM è¿”å›ç»“æœ:", res)
        print("ä½œä¸º Msg çš„å“åº”:", msg_res)


    asyncio.run(example_model_call())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    LLM è¿”å›ç»“æœ: ChatResponse(content=[{'type': 'text', 'text': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}], id='2025-09-20 01:31:31.870_2d014e', created_at='2025-09-20 01:31:31.870', type='chat', usage=ChatUsage(input_tokens=10, output_tokens=7, time=1.489284, type='chat'), metadata=None)
    ä½œä¸º Msg çš„å“åº”: Msg(id='Zj2Q86hcx2bc58cPFQb7Zi', name='Friday', content=[{'type': 'text', 'text': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}], role='assistant', metadata=None, timestamp='2025-09-20 01:31:31.870', invocation_id='None')




.. GENERATED FROM PYTHON SOURCE LINES 121-128

æµå¼è¿”å›
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
è¦å¯ç”¨æµå¼è¿”å›ï¼Œè¯·åœ¨æ¨¡å‹çš„æ„é€ å‡½æ•°ä¸­å°† ``stream`` å‚æ•°è®¾ç½®ä¸º ``True``ã€‚
æµå¼è¿”å›ä¸­ï¼Œ``__call__`` æ–¹æ³•å°†è¿”å›ä¸€ä¸ª **å¼‚æ­¥ç”Ÿæˆå™¨**ï¼Œè¯¥ç”Ÿæˆå™¨è¿­ä»£è¿”å› ``ChatResponse`` å®ä¾‹ã€‚

.. note:: AgentScope ä¸­çš„æµå¼è¿”å›ç»“æœä¸º **ç´¯åŠ å¼**ï¼Œè¿™æ„å‘³ç€æ¯ä¸ª chunk ä¸­çš„å†…å®¹åŒ…å«æ‰€æœ‰ä¹‹å‰çš„å†…å®¹åŠ ä¸Šæ–°ç”Ÿæˆçš„å†…å®¹ã€‚


.. GENERATED FROM PYTHON SOURCE LINES 128-158

.. code-block:: Python



    async def example_streaming() -> None:
        """ä½¿ç”¨æµå¼æ¨¡å‹çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-max",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            stream=True,
        )

        generator = await model(
            messages=[
                {
                    "role": "user",
                    "content": "ä» 1 æ•°åˆ° 20ï¼ŒåªæŠ¥å‘Šæ•°å­—ï¼Œä¸è¦ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚",
                },
            ],
        )
        print("å“åº”çš„ç±»å‹:", type(generator))

        i = 0
        async for chunk in generator:
            print(f"å— {i}")
            print(f"\tç±»å‹: {type(chunk.content)}")
            print(f"\t{chunk}\n")
            i += 1


    asyncio.run(example_streaming())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    å“åº”çš„ç±»å‹: <class 'async_generator'>
    å— 0
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1'}], id='2025-09-20 01:31:32.977_813c95', created_at='2025-09-20 01:31:32.977', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=1, time=1.105463, type='chat'), metadata=None)

    å— 1
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n'}], id='2025-09-20 01:31:33.095_cadfe8', created_at='2025-09-20 01:31:33.095', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=2, time=1.223066, type='chat'), metadata=None)

    å— 2
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2'}], id='2025-09-20 01:31:33.110_2589a8', created_at='2025-09-20 01:31:33.110', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=3, time=1.237804, type='chat'), metadata=None)

    å— 3
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n'}], id='2025-09-20 01:31:33.167_fd92ab', created_at='2025-09-20 01:31:33.167', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=4, time=1.295022, type='chat'), metadata=None)

    å— 4
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n'}], id='2025-09-20 01:31:33.413_70127e', created_at='2025-09-20 01:31:33.413', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=8, time=1.541148, type='chat'), metadata=None)

    å— 5
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n'}], id='2025-09-20 01:31:33.694_5d3beb', created_at='2025-09-20 01:31:33.694', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=12, time=1.82262, type='chat'), metadata=None)

    å— 6
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n'}], id='2025-09-20 01:31:34.664_3fccf7', created_at='2025-09-20 01:31:34.664', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=16, time=2.791982, type='chat'), metadata=None)

    å— 7
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10'}], id='2025-09-20 01:31:34.903_4a9398', created_at='2025-09-20 01:31:34.903', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=20, time=3.031548, type='chat'), metadata=None)

    å— 8
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n'}], id='2025-09-20 01:31:35.170_e49356', created_at='2025-09-20 01:31:35.170', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=24, time=3.297699, type='chat'), metadata=None)

    å— 9
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n1'}], id='2025-09-20 01:31:35.421_db0427', created_at='2025-09-20 01:31:35.421', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=28, time=3.549505, type='chat'), metadata=None)

    å— 10
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14'}], id='2025-09-20 01:31:35.673_ea4021', created_at='2025-09-20 01:31:35.673', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=32, time=3.800738, type='chat'), metadata=None)

    å— 11
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n'}], id='2025-09-20 01:31:35.935_ab9310', created_at='2025-09-20 01:31:35.935', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=36, time=4.063609, type='chat'), metadata=None)

    å— 12
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n1'}], id='2025-09-20 01:31:36.159_8e246f', created_at='2025-09-20 01:31:36.159', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=40, time=4.287597, type='chat'), metadata=None)

    å— 13
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18'}], id='2025-09-20 01:31:36.464_163c2c', created_at='2025-09-20 01:31:36.464', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=44, time=4.592653, type='chat'), metadata=None)

    å— 14
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n'}], id='2025-09-20 01:31:36.721_241573', created_at='2025-09-20 01:31:36.721', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=48, time=4.84891, type='chat'), metadata=None)

    å— 15
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20'}], id='2025-09-20 01:31:36.901_fe4825', created_at='2025-09-20 01:31:36.901', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=50, time=5.029228, type='chat'), metadata=None)

    å— 16
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20'}], id='2025-09-20 01:31:36.922_3e0e32', created_at='2025-09-20 01:31:36.922', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=50, time=5.049813, type='chat'), metadata=None)





.. GENERATED FROM PYTHON SOURCE LINES 159-163

æ¨ç†æ¨¡å‹
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
AgentScope é€šè¿‡æä¾› ``ThinkingBlock`` æ¥æ”¯æŒæ¨ç†æ¨¡å‹ã€‚


.. GENERATED FROM PYTHON SOURCE LINES 163-188

.. code-block:: Python



    async def example_reasoning() -> None:
        """ä½¿ç”¨æ¨ç†æ¨¡å‹çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-turbo",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            enable_thinking=True,
        )

        res = await model(
            messages=[
                {"role": "user", "content": "æˆ‘æ˜¯è°ï¼Ÿ"},
            ],
        )

        last_chunk = None
        async for chunk in res:
            last_chunk = chunk
        print("æœ€ç»ˆå“åº”:")
        print(last_chunk)


    asyncio.run(example_reasoning())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    æœ€ç»ˆå“åº”:
    ChatResponse(content=[{'type': 'thinking', 'thinking': 'å¥½çš„ï¼Œç”¨æˆ·é—®â€œæˆ‘æ˜¯è°ï¼Ÿâ€ï¼Œè¿™æ˜¯ä¸€ä¸ªå“²å­¦æ€§çš„é—®é¢˜ï¼Œå¯èƒ½æ¶‰åŠè‡ªæˆ‘è®¤çŸ¥ã€å­˜åœ¨ä¸»ä¹‰ç­‰ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦è€ƒè™‘ç”¨æˆ·ä¸ºä»€ä¹ˆä¼šé—®è¿™ä¸ªé—®é¢˜ã€‚å¯èƒ½æ˜¯åœ¨æ€è€ƒäººç”Ÿæ„ä¹‰ï¼Œæˆ–è€…å¯¹è‡ªæˆ‘èº«ä»½æ„Ÿåˆ°å›°æƒ‘ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘åº”è¯¥åˆ†æä¸åŒçš„è§’åº¦æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚\n\nä»å¿ƒç†å­¦è§’åº¦çœ‹ï¼Œè‡ªæˆ‘è®¤çŸ¥æ˜¯é€šè¿‡ç»å†å’Œåæ€å½¢æˆçš„ã€‚ç”¨æˆ·å¯èƒ½åœ¨å¯»æ±‚å¯¹è‡ªå·±æ›´æ·±å…¥çš„ç†è§£ã€‚å“²å­¦æ–¹é¢ï¼Œå¯ä»¥å¼•ç”¨ç¬›å¡å°”çš„â€œæˆ‘æ€æ•…æˆ‘åœ¨â€ï¼Œæˆ–è€…å­˜åœ¨ä¸»ä¹‰çš„è§‚ç‚¹ï¼Œå¼ºè°ƒä¸ªä½“çš„è‡ªç”±é€‰æ‹©ã€‚å®—æ•™æˆ–çµæ€§è§’åº¦ï¼Œå¯èƒ½æ¶‰åŠçµé­‚ã€è½®å›ç­‰æ¦‚å¿µã€‚\n\nåŒæ—¶ï¼Œè¦è€ƒè™‘åˆ°ç”¨æˆ·å¯èƒ½çš„èƒŒæ™¯ã€‚å¦‚æœæ˜¯å¹´è½»äººï¼Œå¯èƒ½å¤„äºè‡ªæˆ‘æ¢ç´¢é˜¶æ®µï¼›å¦‚æœæ˜¯æˆå¹´äººï¼Œå¯èƒ½åœ¨ç»å†äººç”Ÿè½¬æŠ˜ç‚¹ã€‚éœ€è¦é¿å…è¿‡äºæŠ½è±¡çš„å›ç­”ï¼Œå°½é‡ç»“åˆå®é™…ä¾‹å­ï¼Œè®©ç”¨æˆ·æ›´å®¹æ˜“ç†è§£ã€‚\n\nè¿˜è¦æ³¨æ„ä¸è¦ç»™å‡ºç»å¯¹çš„ç­”æ¡ˆï¼Œå› ä¸ºè¿™ä¸ªé—®é¢˜æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆã€‚åº”è¯¥é¼“åŠ±ç”¨æˆ·è‡ªæˆ‘åæ€ï¼Œå¹¶æä¾›ä¸åŒçš„è§†è§’ä¾›å‚è€ƒã€‚æ­¤å¤–ï¼Œå¯èƒ½éœ€è¦è¯¢é—®ç”¨æˆ·çš„å…·ä½“æƒ…å¢ƒï¼Œä»¥ä¾¿æä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„å›ç­”ï¼Œä½†æ ¹æ®å½“å‰é—®é¢˜ï¼Œä¿æŒå¼€æ”¾æ€§å›ç­”æ›´åˆé€‚ã€‚\n\næœ€åï¼Œç¡®ä¿è¯­è¨€äº²åˆ‡ï¼Œé¿å…å­¦æœ¯åŒ–ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°è¢«ç†è§£å’Œæ”¯æŒã€‚å¯èƒ½éœ€è¦æé†’ç”¨æˆ·ï¼Œè‡ªæˆ‘è®¤çŸ¥æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œé¼“åŠ±ä»–ä»¬ç»§ç»­æ¢ç´¢ã€‚'}, {'type': 'text', 'text': 'â€œæˆ‘æ˜¯è°ï¼Ÿâ€è¿™ä¸ªé—®é¢˜çœ‹ä¼¼ç®€å•ï¼Œå´è•´å«ç€æ·±åˆ»çš„å“²å­¦ä¸è‡ªæˆ‘æ¢ç´¢çš„æ„ä¹‰ã€‚ä¸åŒçš„äººã€ä¸åŒçš„é˜¶æ®µå¯èƒ½ä¼šæœ‰ä¸åŒçš„ç­”æ¡ˆã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½çš„æ€è€ƒæ–¹å‘ï¼Œæˆ–è®¸èƒ½å¸®åŠ©ä½ æ›´æ¥è¿‘è‡ªå·±çš„ç­”æ¡ˆï¼š\n\n---\n\n### 1. **ä»å­˜åœ¨ä¸»ä¹‰çš„è§’åº¦**  \n   - **â€œæˆ‘æ€æ•…æˆ‘åœ¨â€**ï¼ˆç¬›å¡å°”ï¼‰ï¼šä½ çš„æ€è€ƒã€æ„Ÿå—ã€é€‰æ‹©æœ¬èº«ï¼Œå°±æ˜¯ä½ å­˜åœ¨çš„è¯æ˜ã€‚ä½ æ˜¯ä¸€ä¸ªèƒ½åæ€ã€èƒ½æé—®çš„ä¸»ä½“ã€‚  \n   - **â€œæˆ‘æ˜¯è‡ªç”±çš„â€**ï¼ˆè¨ç‰¹ï¼‰ï¼šä½ å¹¶éè¢«å®šä¹‰çš„â€œè°â€ï¼Œè€Œæ˜¯é€šè¿‡æ¯ä¸€æ¬¡é€‰æ‹©ã€è¡ŒåŠ¨å’Œå†³å®šï¼Œä¸æ–­å¡‘é€ è‡ªå·±çš„èº«ä»½ã€‚  \n\n---\n\n### 2. **ä»å¿ƒç†å­¦çš„è§’åº¦**  \n   - **è‡ªæˆ‘è®¤çŸ¥**ï¼šä½ å¯èƒ½æ˜¯â€œè¿‡å»ç»å†çš„æ€»å’Œâ€â€”â€”ä½ çš„æ€§æ ¼ã€ä¹ æƒ¯ã€ä»·å€¼è§‚ï¼Œéƒ½æºäºæˆé•¿ç¯å¢ƒã€æ•™è‚²ã€äººé™…å…³ç³»ç­‰ã€‚  \n   - **åŠ¨æ€çš„è‡ªæˆ‘**ï¼šä½ ä¸æ˜¯ä¸€æˆä¸å˜çš„â€œè°â€ï¼Œè€Œæ˜¯ä¸€ä¸ªä¸æ–­å˜åŒ–çš„ä¸ªä½“ã€‚ä»Šå¤©çš„ä½ å¯èƒ½ä¸æ˜¨å¤©çš„ä½ ä¸åŒï¼Œæœªæ¥çš„ä½ ä¹Ÿå¯èƒ½è¶…è¶Šç°åœ¨çš„è‡ªå·±ã€‚  \n\n---\n\n### 3. **ä»çµæ€§æˆ–å“²å­¦çš„è§’åº¦**  \n   - **â€œæˆ‘æ˜¯è°â€æ˜¯ä¿®è¡Œçš„èµ·ç‚¹**ï¼šè®¸å¤šçµæ€§ä¼ ç»Ÿï¼ˆå¦‚ä½›æ•™ã€å°åº¦æ•™ï¼‰è®¤ä¸ºï¼ŒçœŸæ­£çš„â€œæˆ‘â€å¹¶éè‚‰ä½“æˆ–åå­—ï¼Œè€Œæ˜¯è¶…è¶Šè¡¨è±¡çš„æœ¬ä½“ã€‚  \n   - **â€œæˆ‘æ˜¯å…‰â€**ï¼ˆåŸºç£æ•™ï¼‰æˆ–â€œæˆ‘æ˜¯é“â€ï¼ˆé“æ•™ï¼‰ï¼šæŸäº›ä¿¡ä»°ä½“ç³»å°†â€œæˆ‘â€è§†ä¸ºå®‡å®™æˆ–çœŸç†çš„ä¸€éƒ¨åˆ†ï¼Œè¶…è¶Šä¸ªä½“çš„å±€é™ã€‚  \n\n---\n\n### 4. **ä»æ—¥å¸¸ç”Ÿæ´»çš„è§’åº¦**  \n   - **èº«ä»½æ ‡ç­¾**ï¼šä½ å¯èƒ½æ˜¯æŸä¸ªèŒä¸šã€å®¶åº­è§’è‰²ï¼ˆå¦‚çˆ¶æ¯ã€å­å¥³ï¼‰ã€å…´è¶£çˆ±å¥½çš„é›†åˆã€‚  \n   - **æ›´æ·±å±‚çš„è‡ªæˆ‘**ï¼šä¹Ÿè®¸ä½ æ›´åœ¨æ„çš„æ˜¯â€œæˆ‘æƒ³è¦ä»€ä¹ˆâ€â€œæˆ‘ä¸ºä»€ä¹ˆæ´»ç€â€â€œæˆ‘å¦‚ä½•ä¸ä¸–ç•Œè¿æ¥â€ã€‚  \n\n---\n\n### 5. **å¦‚æœè¿™æ˜¯ä½ æ­¤åˆ»çš„å›°æƒ‘**  \n   - **å…è®¸è‡ªå·±ä¸ç¡®å®š**ï¼šå¾ˆå¤šäººä¸€ç”Ÿéƒ½åœ¨è¿½é—®â€œæˆ‘æ˜¯è°â€ï¼Œè¿™æœ¬èº«æ˜¯æˆé•¿çš„ä¸€éƒ¨åˆ†ã€‚  \n   - **é€šè¿‡è¡ŒåŠ¨æ¢ç´¢**ï¼šå°è¯•æ–°äº‹ç‰©ã€ä¸ä»–äººäº¤æµã€è®°å½•å†…å¿ƒæ„Ÿå—ï¼Œå¯èƒ½ä¼šé€æ¸å‘ç°æ›´æ¸…æ™°çš„ç­”æ¡ˆã€‚  \n   - **æ¥çº³â€œæœªå®Œæˆâ€çš„è‡ªå·±**ï¼šä½ ä¸éœ€è¦ç«‹åˆ»æ‰¾åˆ°å…¨éƒ¨ç­”æ¡ˆï¼Œç”Ÿå‘½çš„å¤æ‚æ€§æ­£æ˜¯å®ƒçš„é­…åŠ›æ‰€åœ¨ã€‚  \n\n---\n\n### æœ€åï¼Œæˆ–è®¸å¯ä»¥è¿™æ ·æƒ³ï¼š  \n**â€œæˆ‘æ˜¯è°â€ä¸æ˜¯ä¸€ä¸ªéœ€è¦è¢«è§£ç­”çš„è°œé¢˜ï¼Œè€Œæ˜¯ä¸€æ®µæŒç»­çš„æ—…ç¨‹ã€‚**  \næ¯ä¸€æ¬¡æé—®ï¼Œéƒ½æ˜¯ä½ ä¸è‡ªå·±å¯¹è¯çš„å¼€å§‹ã€‚ä½ ä¸éœ€è¦æ€¥äºæ‰¾åˆ°ç»ˆç‚¹ï¼Œåªéœ€å¸¦ç€å¥½å¥‡å’Œå‹‡æ°”ï¼Œç»§ç»­å‰è¡Œã€‚  \n\nå¦‚æœä½ æ„¿æ„åˆ†äº«æ›´å¤šèƒŒæ™¯ï¼Œæˆ‘ä¹Ÿå¯ä»¥å°è¯•æ›´å…·ä½“åœ°å¸®ä½ åˆ†æ~ ğŸŒ±'}], id='2025-09-20 01:31:46.001_3ba4a9', created_at='2025-09-20 01:31:46.001', type='chat', usage=ChatUsage(input_tokens=11, output_tokens=805, time=9.074034, type='chat'), metadata=None)




.. GENERATED FROM PYTHON SOURCE LINES 189-197

å·¥å…· API
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ä¸åŒçš„æ¨¡å‹æä¾›å•†åœ¨å·¥å…· API æ–¹é¢æœ‰æ‰€ä¸åŒï¼Œä¾‹å¦‚å·¥å…· JSON schemaã€å·¥å…·è°ƒç”¨/å“åº”æ ¼å¼ã€‚
ä¸ºäº†æä¾›ç»Ÿä¸€çš„æ¥å£ï¼ŒAgentScope é€šè¿‡ä»¥ä¸‹æ–¹å¼è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼š

- æä¾›äº†ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨ç»“æ„ block :ref:`ToolUseBlock <tool-block>` å’Œå·¥å…·å“åº”ç»“æ„ :ref:`ToolResultBlock <tool-block>`ã€‚
- åœ¨æ¨¡å‹ç±»çš„ ``__call__`` æ–¹æ³•ä¸­æä¾›ç»Ÿä¸€çš„å·¥å…·æ¥å£ ``tools``ï¼Œæ¥å—å·¥å…· JSON schema åˆ—è¡¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š


.. GENERATED FROM PYTHON SOURCE LINES 197-218

.. code-block:: Python


    json_schemas = [
        {
            "type": "function",
            "function": {
                "name": "google_search",
                "description": "åœ¨ Google ä¸Šæœç´¢æŸ¥è¯¢ã€‚",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢æŸ¥è¯¢ã€‚",
                        },
                    },
                    "required": ["query"],
                },
            },
        },
    ]








.. GENERATED FROM PYTHON SOURCE LINES 219-224

è¿›ä¸€æ­¥é˜…è¯»
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- :ref:`message`
- :ref:`prompt`



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 15.627 seconds)


.. _sphx_glr_download_tutorial_task_model.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: task_model.ipynb <task_model.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: task_model.py <task_model.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: task_model.zip <task_model.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
